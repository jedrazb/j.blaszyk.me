"use strict";(self.webpackChunkj_blaszyk_me=self.webpackChunkj_blaszyk_me||[]).push([[411],{1546:function(e,n,a){a.r(n),a.d(n,{default:function(){return T}});var t=a(7387),s=a(8453),o=a(6540);function l(e){const n=Object.assign({p:"p",a:"a",span:"span",blockquote:"blockquote",h2:"h2",ul:"ul",li:"li",em:"em",ol:"ol"},(0,s.R)(),e.components),{ImageComponent:a}=n;return a||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("ImageComponent",!0),o.createElement(o.Fragment,null,o.createElement(n.p,null,"Let’s use ",o.createElement(n.a,{href:"https://github.com/Yelp/nrtsearch",target:"_blank",rel:"nofollow noopener noreferrer"},"nrtsearch")," - an open-source search engine built by Yelp - to support text search for any website. In this tutorial, I’m using my blog as an example dataset, but you can apply this approach to index any kind of data."),"\n",o.createElement(n.p,null,"The plan is to build a simple web crawler to fetch website’s data. Then we start a local nrtsearch cluster with a primary and replicas, design its index schema and set up an indexing pipeline for the search engine. Finally, we define nrtsearch queries to support custom scoring and highlighting. A simple search UI will allow us to interact with the system. All of this will be done with minimal coding. I will use open-source libraries to keep things simple and extensible. You can clone ",o.createElement(n.a,{href:"https://github.com/jedrazb/nrtsearch-tutorial-website-search",target:"_blank",rel:"nofollow noopener noreferrer"},"the tutorial code repo")," to run the code locally. All you need is ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">python3</code>'}})," and ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">Docker</code>'}})," installed on your system."),"\n",o.createElement(n.p,null,"If you want to learn more about nrtsearch, check out Yelp’s Engineering blog post:"),"\n",o.createElement(n.blockquote,null,"\n",o.createElement(n.p,null,o.createElement(n.a,{href:"https://engineeringblog.yelp.com/2021/09/nrtsearch-yelps-fast-scalable-and-cost-effective-search-engine.html",target:"_blank",rel:"nofollow noopener noreferrer"},"Nrtsearch: Yelp’s Fast, Scalable and Cost Effective Search Engine")),"\n"),"\n",o.createElement(n.p,null,"Let’s start!"),"\n",o.createElement(n.h2,{id:"web-crawler",style:{position:"relative"}},o.createElement(n.a,{href:"#web-crawler","aria-label":"web crawler permalink",className:"anchor before"},o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Web crawler"),"\n",o.createElement(n.p,null,"The crawler fetches data from websites. In this tutorial I’m using my blog as an example dataset. For simplicity, I supplied a sitemap - a list of urls - so that the crawler can directly fetch the data."),"\n",o.createElement(n.p,null,"I use ",o.createElement(n.a,{href:"https://beautiful-soup-4.readthedocs.io/en/latest/",target:"_blank",rel:"nofollow noopener noreferrer"},"beautifulsoup")," library for extracting website content. The website data can be represented in a following way:"),"\n",o.createElement(n.ul,null,"\n",o.createElement(n.li,null,o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">title</code>'}})," - website title tag"),"\n",o.createElement(n.li,null,o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">description</code>'}})," - meta description tag, a short summary of the website, provided by the author"),"\n",o.createElement(n.li,null,o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">url</code>'}})," - unique website id"),"\n",o.createElement(n.li,null,o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">content</code>'}}),"- extracted text content, e.g. paragraphs"),"\n",o.createElement(n.li,null,o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">headings</code>'}})," - extracted website’s headings, we group ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">h1</code>'}}),", ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">h2</code>'}}),", ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">h3</code>'}}),", … tags together."),"\n"),"\n",o.createElement(n.p,null,"Our code uses ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">get_source_urls()</code>'}})," function to get the list of urls. The function will process the HTML pages to extract: title, description, content and headings. After it’s done, it will save the output to a JSON file."),"\n",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> json\n<span class="token keyword">import</span> requests\n<span class="token keyword">from</span> bs4 <span class="token keyword">import</span> BeautifulSoup\n\nurls <span class="token operator">=</span> get_source_urls<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># urls from website sitemap</span>\n\nwebsite_data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>\n\n<span class="token keyword">for</span> url <span class="token keyword">in</span> urls<span class="token punctuation">:</span>\n    response <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">)</span>\n    soup <span class="token operator">=</span> BeautifulSoup<span class="token punctuation">(</span>response<span class="token punctuation">.</span>content<span class="token punctuation">,</span> <span class="token string">"html.parser"</span><span class="token punctuation">)</span>\n\n    title <span class="token operator">=</span> soup<span class="token punctuation">.</span>title<span class="token punctuation">.</span>text<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> soup<span class="token punctuation">.</span>title <span class="token keyword">else</span> <span class="token boolean">None</span>\n    description <span class="token operator">=</span> <span class="token punctuation">(</span>\n        soup<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">"meta"</span><span class="token punctuation">,</span> attrs<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">"name"</span><span class="token punctuation">:</span> <span class="token string">"description"</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">"content"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>\n        <span class="token keyword">if</span> soup<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">"meta"</span><span class="token punctuation">,</span> attrs<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">"name"</span><span class="token punctuation">:</span> <span class="token string">"description"</span><span class="token punctuation">}</span><span class="token punctuation">)</span>\n        <span class="token keyword">else</span> <span class="token boolean">None</span>\n    <span class="token punctuation">)</span>\n    headings <span class="token operator">=</span> <span class="token punctuation">[</span>\n        h<span class="token punctuation">.</span>text<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> h <span class="token keyword">in</span> soup<span class="token punctuation">.</span>find_all<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"h1"</span><span class="token punctuation">,</span> <span class="token string">"h2"</span><span class="token punctuation">,</span> <span class="token string">"h3"</span><span class="token punctuation">,</span> <span class="token string">"h4"</span><span class="token punctuation">,</span> <span class="token string">"h5"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>\n    <span class="token punctuation">]</span>\n    content <span class="token operator">=</span> soup<span class="token punctuation">.</span>get_text<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">,</span> strip<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>\n\n    website_data<span class="token punctuation">.</span>append<span class="token punctuation">(</span>\n        <span class="token punctuation">{</span>\n            <span class="token string">"url"</span><span class="token punctuation">:</span> url<span class="token punctuation">,</span>\n            <span class="token string">"title"</span><span class="token punctuation">:</span> title<span class="token punctuation">,</span>\n            <span class="token string">"description"</span><span class="token punctuation">:</span> description<span class="token punctuation">,</span>\n            <span class="token string">"headings"</span><span class="token punctuation">:</span> headings<span class="token punctuation">,</span>\n            <span class="token string">"content"</span><span class="token punctuation">:</span> content<span class="token punctuation">,</span>\n        <span class="token punctuation">}</span>\n    <span class="token punctuation">)</span>\n\n<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">\'index_resources/website_data.json\'</span><span class="token punctuation">,</span> <span class="token string">\'w\'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> outfile<span class="token punctuation">:</span>\n    json<span class="token punctuation">.</span>dump<span class="token punctuation">(</span>website_data<span class="token punctuation">,</span> outfile<span class="token punctuation">)</span>\n</code></pre></div>'}}),"\n",o.createElement(n.p,null,"The full crawler code is located in ",o.createElement(n.a,{href:"https://github.com/jedrazb/nrtsearch-tutorial-website-search/blob/master/crawler/crawler.py",target:"_blank",rel:"nofollow noopener noreferrer"},"crawler/crawler.py"),", you can run the crawler by executing:"),"\n",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">make</span> run_crawler</code></pre></div>'}}),"\n",o.createElement(n.h2,{id:"nrtsearch-cluster",style:{position:"relative"}},o.createElement(n.a,{href:"#nrtsearch-cluster","aria-label":"nrtsearch cluster permalink",className:"anchor before"},o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Nrtsearch cluster"),"\n",o.createElement(n.p,null,"The nrtsearch cluster consists of 2 types of nodes:"),"\n",o.createElement(n.ul,null,"\n",o.createElement(n.li,null,o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">primary</code>'}})," - a single node, responsible for data indexing. It periodically publishes Lucene segment updates to replicas. Hence the name: ",o.createElement(n.em,null,"nrtsearch - near-real time search"),"."),"\n",o.createElement(n.li,null,o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">replica</code>'}})," - one or more nodes, responsible for serving the search traffic. It receives periodic segment updates from the primary. The number of running replicas can be controlled by an auto-scaler (like ",o.createElement(n.a,{href:"https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/",target:"_blank",rel:"nofollow noopener noreferrer"},"HPA"),") to respond to changing search load."),"\n"),"\n",o.createElement(n.p,null,"It’s also possible to run the cluster with a single, standalone node, used for both data ingestion and search. It’s ok for experimentation but for production environments it’s recommended to run separate primary and replica nodes."),"\n",o.createElement(n.p,null,"The source code for nrtsearch cluster setup is available in ",o.createElement(n.a,{href:"https://github.com/jedrazb/nrtsearch-tutorial-website-search/tree/master/nrtsearch",target:"_blank",rel:"nofollow noopener noreferrer"},"/nrtsearch")," folder. There we have:"),"\n",o.createElement(n.ul,null,"\n",o.createElement(n.li,null,o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">Dockerfile</code>'}})," to setup an nrtsearch node"),"\n",o.createElement(n.li,null,"configs for primary and replicas"),"\n",o.createElement(n.li,null,o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">docker-compose.yaml</code>'}})," with example cluster configuration"),"\n"),"\n",o.createElement(n.p,null,"Note: in this tutorial we don’t worry about persisting the index state. If you rebuild your nrtsearch containers, all index state will be lost. In order to persist your index, you can attach a permanent volume to docker containers. For production, it’s advisable to use a dedicated s3 bucket where nrtsearch stores the cluster state - it allows deploying nrtsearch as a stateless service. More about possible configurations in ",o.createElement(n.a,{href:"https://nrtsearch.readthedocs.io/en/latest/server_configuration.html",target:"_blank",rel:"nofollow noopener noreferrer"},"nrtsearch docs"),"."),"\n",o.createElement(n.p,null,"In order to start the local cluster with a primary and two replicas, run a following command in a separate terminal window:"),"\n",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">make</span> start</code></pre></div>'}}),"\n",o.createElement(n.p,null,"Above command will run ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">docker compose up</code>'}})," that starts the nrtsearch cluster defined in the root ",o.createElement(n.a,{href:"https://github.com/jedrazb/nrtsearch-tutorial-website-search/blob/master/docker-compose.yaml",target:"_blank",rel:"nofollow noopener noreferrer"},"docker-compose.yaml")," file. It will also start a few other services that will be described later. In your terminal window you should see logs indicating that the primary and replicas are ready:"),"\n",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">primary-node-1        <span class="token operator">|</span> <span class="token punctuation">[</span>INFO <span class="token punctuation">]</span> <span class="token number">2023</span>-04-16 <span class="token number">12</span>:12:42.194 <span class="token punctuation">[</span>main<span class="token punctuation">]</span> LuceneServer - Server started, listening on <span class="token number">8000</span> <span class="token keyword">for</span> messages</code></pre></div>'}}),"\n",o.createElement(n.p,null,"The address of nrtsearch nodes depends on whether you connect to them from the host machine of from a different docker container."),"\n",o.createElement(n.ul,null,"\n",o.createElement(n.li,null,"For the host machine, the nrtsearch gRPC server (",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">8000</code>'}})," container port) of each node in the cluster is exposed on a host’s physical port. We use port ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">8000</code>'}})," for the primary node and ports ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">8001</code>'}})," and ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">8002</code>'}})," for the two replicas."),"\n",o.createElement(n.li,null,"Within docker containers, we can use docker DNS. ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">primary-node</code>'}})," hostname is used to advertise the primary. All replicas run under the ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">replica-node</code>'}})," hostname. For all nrtsearch nodes the gRPC server runs on port ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">8000</code>'}}),"."),"\n"),"\n",o.createElement(n.p,null,"You can run ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">docker compose ps</code>'}}),", to see ports assigned to containers."),"\n",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">NAME                   IMAGE                COMMAND                  SERVICE              CREATED             STATUS              PORTS\nprimary-node-1         primary-node         <span class="token string">"bash -c \'/user/nrts…"</span>   primary-node         About an hour ago   Up About an hour    <span class="token number">0.0</span>.0.0:8000-<span class="token operator">></span><span class="token number">8000</span>/tcp\nreplica-node-1         replica-node         <span class="token string">"./entrypoint_replic…"</span>   replica-node         About an hour ago   Up About an hour    <span class="token number">0.0</span>.0.0:8002-<span class="token operator">></span><span class="token number">8000</span>/tcp\nreplica-node-2         replica-node         <span class="token string">"./entrypoint_replic…"</span>   replica-node         About an hour ago   Up About an hour    <span class="token number">0.0</span>.0.0:8001-<span class="token operator">></span><span class="token number">8000</span>/tcp</code></pre></div>'}}),"\n",o.createElement(n.p,null,"Great! Now we have a local nrtsearch cluster with nodes dedicated to data ingestion and search. Even though the containers are now running, no index was created. A new index must be created via a command. Once the index has been started in replicas, they register with the primary. Replication happens only after documents are ingested into the primary."),"\n",o.createElement(n.p,null,"Now, let’s prepare the client code to interact with our cluster."),"\n",o.createElement(n.h2,{id:"generate-grpc-client-code-using-protoc",style:{position:"relative"}},o.createElement(n.a,{href:"#generate-grpc-client-code-using-protoc","aria-label":"generate grpc client code using protoc permalink",className:"anchor before"},o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Generate gRPC client code using protoc"),"\n",o.createElement(n.p,null,"Clients can communicate with nrtsearch via gRPC or REST API. ",o.createElement(n.a,{href:"https://grpc.io/",target:"_blank",rel:"nofollow noopener noreferrer"},"gRPC")," is a high-performance remote procedure call framework that enables communication using protocol buffers. This method yields high performance for production applications. The REST API is an optional way to communicate with nrtsearch, suitable for development and experimentation. The REST server (",o.createElement(n.a,{href:"https://github.com/grpc-ecosystem/grpc-gateway",target:"_blank",rel:"nofollow noopener noreferrer"},"grpc-gateway"),") is autogenerated from ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">proto</code>'}})," definitions."),"\n",o.createElement(n.p,null,"Let’s use gRPC to communicate with nrtsearch. Since it’s not a REST API we can’t just ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">curl</code>'}})," the endpoints. We need to generate the native client code, ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">python</code>'}})," for this tutorial, to interact with nrtsearch nodes."),"\n",o.createElement(n.p,null,"To generate Python client code from ",o.createElement(n.a,{href:"https://github.com/Yelp/nrtsearch/tree/master/clientlib/src/main/proto/yelp/nrtsearch",target:"_blank",rel:"nofollow noopener noreferrer"},"nrtsearch proto definitions"),", you can use the gRPC toolchain’s ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">protoc</code>'}})," compiler along with the ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">grpc_tools</code>'}})," package to compile the ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">.proto</code>'}})," files into Python code. You can then use the generated client code to communicate with the gRPC server. The steps are:"),"\n",o.createElement(n.ul,null,"\n",o.createElement(n.li,null,"get all nrtsearch ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">.proto</code>'}})," files along with their dependencies to a folder, let’s call it ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">/protos</code>'}})),"\n",o.createElement(n.li,null,"point ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">protoc</code>'}})," compiler to ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">/protos</code>'}})," folder and generate the python code"),"\n"),"\n",o.createElement(n.p,null,"In the ",o.createElement(n.a,{href:"https://github.com/jedrazb/nrtsearch-tutorial-website-search/blob/master/Makefile",target:"_blank",rel:"nofollow noopener noreferrer"},"Makefile")," there are commands ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">nrtsearch_protos</code>'}})," and ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">nrtsearch_protos</code>'}})," which execute the steps above. They will put the generated code into ",o.createElement(n.a,{href:"https://github.com/jedrazb/nrtsearch-tutorial-website-search/tree/master/nrtsearch_client/yelp/nrtsearch",target:"_blank",rel:"nofollow noopener noreferrer"},"nrtsearch_client/yelp/nrtsearch/"),"."),"\n",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<div class="gatsby-highlight" data-language="makefile"><pre class="language-makefile"><code class="language-makefile"><span class="token comment"># Generate nrtsearch .proto files and their dependencies</span>\n<span class="token target symbol">nrtsearch_protos</span><span class="token punctuation">:</span>\n\tmkdir -p protos\n<span class="token target symbol">\tdocker build -t nrtsearch-protos-builder</span><span class="token punctuation">:</span>latest ./utils/nrtsearch_protos_builder/\n<span class="token target symbol">\tdocker run -v <span class="token variable">$</span>(shell pwd)/protos</span><span class="token punctuation">:</span>/user/protos  nrtsearch-protos-builder<span class="token punctuation">:</span>latest\n\n<span class="token comment"># Compile client .proto files to python code</span>\n<span class="token target symbol">nrtsearch_protoc</span><span class="token punctuation">:</span> nrtsearch_protos\n\t<span class="token variable">$</span><span class="token punctuation">(</span>PYTHON<span class="token punctuation">)</span> -m grpc_tools.protoc \\\n\t\t--proto_path protos \\\n\t\t--grpc_python_out nrtsearch_client \\\n\t\t--python_out nrtsearch_client \\\n\t\tprotos/yelp/nrtsearch/luceneserver.proto \\\n\t\tprotos/yelp/nrtsearch/search.proto \\\n\t\tprotos/yelp/nrtsearch/analysis.proto \\\n\t\tprotos/yelp/nrtsearch/suggest.proto\n\trm -rf protos</code></pre></div>'}}),"\n",o.createElement(n.p,null,"In order to nrtsearch ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">.proto</code>'}})," files and their dependencies we use a simple ",o.createElement(n.a,{href:"https://github.com/jedrazb/nrtsearch-tutorial-website-search/blob/master/utils/nrtsearch_protos_builder/Dockerfile",target:"_blank",rel:"nofollow noopener noreferrer"},"Dockerfile")," that compiles the project and moves all proto files into the persistent volume ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">/protos</code>'}}),". Then protoc compiler compiles them to python code. After running ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">make nrtsearch_protoc</code>'}})," you can verify that the client code was generated successfully:"),"\n",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">ls</span> nrtsearch_client/yelp/nrtsearch/\nanalysis_pb2.py          luceneserver_pb2.py      search_pb2.py            suggest_pb2.py\nanalysis_pb2_grpc.py     luceneserver_pb2_grpc.py search_pb2_grpc.py       suggest_pb2_grpc.py</code></pre></div>'}}),"\n",o.createElement(n.h2,{id:"index-schema",style:{position:"relative"}},o.createElement(n.a,{href:"#index-schema","aria-label":"index schema permalink",className:"anchor before"},o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Index schema"),"\n",o.createElement(n.p,null,"In order to ingest the data into nrtsearch, we must first create an index and register the fields. Appropriate schema design will enable efficient search and results highlighting for blog data."),"\n",o.createElement(n.p,null,"The ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">blog_search</code>'}})," index needs to represent the data returned from ",o.createElement(n.a,{href:"/tech-blog/nrtsearch-tutorial-website-search/#web-crawler"},"the crawler"),": url, title, description, headings and text content."),"\n",o.createElement(n.ul,null,"\n",o.createElement(n.li,null,"We use ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">TEXT</code>'}})," type for each field, as this allows to the data to be tokenized and indexed with index-time analyzer."),"\n",o.createElement(n.li,null,"The nested field ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">url.id</code>'}})," has ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">_ID</code>'}})," type - it defines the unique Lucene document id. Note, the ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">url</code>'}})," field has ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">TEXT</code>'}})," type as we still want to search for keywords within the url"),"\n",o.createElement(n.li,null,"Each field is searchable (",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">search: true</code>'}}),"), tokenized (",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">tokenize: true</code>'}}),") and is stored in column-oriented way (",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">storeDocValues: true</code>'}}),")."),"\n",o.createElement(n.li,null,"The ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">content.analyzed</code>'}})," field contains the index-time analyzed webpage content. We define a custom analyzer which removes any html characters (",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">htmlstrip</code>'}})," charFilter), uses ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">standard</code>'}})," tokenizer and ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">kStem</code>'}}),", ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">stop</code>'}})," and ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">lowercase</code>'}})," Lucene token filters. In order to support the ",o.createElement(n.a,{href:"https://nrtsearch.readthedocs.io/en/latest/highlighting.html",target:"_blank",rel:"nofollow noopener noreferrer"},"Fast Vector Highlighter")," for results highlighting, we set ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">termVectors</code>'}}),", ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">store</code>'}})," and ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">tokenize</code>'}})," properties."),"\n"),"\n",o.createElement(n.p,null,"The ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">blog_search</code>'}})," index schema is located in ",o.createElement(n.a,{href:"https://github.com/jedrazb/nrtsearch-tutorial-website-search/blob/master/index_resources/index_schema.yaml",target:"_blank",rel:"nofollow noopener noreferrer"},"index_resources/index_schema.yaml")," and defined as:"),"\n",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<div class="gatsby-highlight" data-language="yaml"><pre class="language-yaml"><code class="language-yaml"><span class="token key atrule">indexName</span><span class="token punctuation">:</span> blog_search\n<span class="token key atrule">field</span><span class="token punctuation">:</span>\n  <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> url\n    <span class="token key atrule">type</span><span class="token punctuation">:</span> TEXT\n    <span class="token key atrule">search</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>\n    <span class="token key atrule">storeDocValues</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>\n    <span class="token key atrule">tokenize</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>\n    <span class="token key atrule">childFields</span><span class="token punctuation">:</span>\n      <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> id\n        <span class="token key atrule">type</span><span class="token punctuation">:</span> _ID\n        <span class="token key atrule">search</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>\n        <span class="token key atrule">storeDocValues</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>\n  <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> title\n    <span class="token key atrule">type</span><span class="token punctuation">:</span> TEXT\n    <span class="token key atrule">search</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>\n    <span class="token key atrule">storeDocValues</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>\n    <span class="token key atrule">tokenize</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>\n  <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> description\n    <span class="token key atrule">type</span><span class="token punctuation">:</span> TEXT\n    <span class="token key atrule">search</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>\n    <span class="token key atrule">storeDocValues</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>\n    <span class="token key atrule">tokenize</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>\n  <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> headings\n    <span class="token key atrule">type</span><span class="token punctuation">:</span> TEXT\n    <span class="token key atrule">search</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>\n    <span class="token key atrule">storeDocValues</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>\n    <span class="token key atrule">tokenize</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>\n    <span class="token key atrule">multiValued</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>\n  <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> content\n    <span class="token key atrule">type</span><span class="token punctuation">:</span> TEXT\n    <span class="token key atrule">search</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>\n    <span class="token key atrule">storeDocValues</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>\n    <span class="token key atrule">tokenize</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>\n    <span class="token key atrule">store</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>\n    <span class="token key atrule">termVectors</span><span class="token punctuation">:</span> TERMS_POSITIONS_OFFSETS\n    <span class="token key atrule">childFields</span><span class="token punctuation">:</span>\n      <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> analyzed\n        <span class="token key atrule">type</span><span class="token punctuation">:</span> TEXT\n        <span class="token key atrule">search</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>\n        <span class="token key atrule">store</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>\n        <span class="token key atrule">termVectors</span><span class="token punctuation">:</span> TERMS_POSITIONS_OFFSETS\n        <span class="token key atrule">tokenize</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>\n        <span class="token key atrule">analyzer</span><span class="token punctuation">:</span>\n          <span class="token key atrule">custom</span><span class="token punctuation">:</span>\n            <span class="token key atrule">charFilters</span><span class="token punctuation">:</span>\n              <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> htmlstrip\n            <span class="token key atrule">tokenizer</span><span class="token punctuation">:</span>\n              <span class="token key atrule">name</span><span class="token punctuation">:</span> standard\n            <span class="token key atrule">tokenFilters</span><span class="token punctuation">:</span>\n              <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> lowercase\n              <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> kStem\n              <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> stop</code></pre></div>'}}),"\n",o.createElement(n.p,null,"More information about the nrtsearch field types, schema design and supported analyzers is available in the ",o.createElement(n.a,{href:"https://nrtsearch.readthedocs.io/en/latest/analysis.html",target:"_blank",rel:"nofollow noopener noreferrer"},"nrtsearch docs"),"."),"\n",o.createElement(n.h2,{id:"create-nrtsearch-index",style:{position:"relative"}},o.createElement(n.a,{href:"#create-nrtsearch-index","aria-label":"create nrtsearch index permalink",className:"anchor before"},o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Create nrtsearch index"),"\n",o.createElement(n.p,null,"Now it’s time to create and start an index for blog data. We have a running nrtsearch cluster, generated client code and the index schema."),"\n",o.createElement(n.p,null,"To configure the index on primary and replicas, we need to run several requests in order."),"\n",o.createElement(n.ol,null,"\n",o.createElement(n.li,null,o.createElement(n.a,{href:"https://github.com/Yelp/nrtsearch/blob/master/clientlib/src/main/proto/yelp/nrtsearch/luceneserver.proto#L428",target:"_blank",rel:"nofollow noopener noreferrer"},"CreateIndexRequest")," - creates the nrtsearch index with a given name"),"\n",o.createElement(n.li,null,o.createElement(n.a,{href:"https://github.com/Yelp/nrtsearch/blob/master/clientlib/src/main/proto/yelp/nrtsearch/luceneserver.proto#L594",target:"_blank",rel:"nofollow noopener noreferrer"},"SettingsRequest")," - sets Lucene-related index settings"),"\n",o.createElement(n.li,null,o.createElement(n.a,{href:"https://github.com/Yelp/nrtsearch/blob/master/clientlib/src/main/proto/yelp/nrtsearch/luceneserver.proto#L628",target:"_blank",rel:"nofollow noopener noreferrer"},"StartIndexRequest")," - starts the index in a given mode (",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">STANDALONE</code>'}}),", ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">PRIMARY</code>'}})," or ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">REPLICA</code>'}}),"), additionally for replicas we need to specify primary ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">host:port</code>'}})," for index replication"),"\n",o.createElement(n.li,null,o.createElement(n.a,{href:"https://github.com/Yelp/nrtsearch/blob/master/clientlib/src/main/proto/yelp/nrtsearch/luceneserver.proto#L583",target:"_blank",rel:"nofollow noopener noreferrer"},"FieldDefRequest")," - registers index schema"),"\n",o.createElement(n.li,null,o.createElement(n.a,{href:"https://github.com/Yelp/nrtsearch/blob/master/clientlib/src/main/proto/yelp/nrtsearch/luceneserver.proto#L687",target:"_blank",rel:"nofollow noopener noreferrer"},"CommitRequest")," - commits the newly created index. It ensures its state is preserved in s3 or other persistent storage"),"\n"),"\n",o.createElement(n.p,null,"Each docker compose container has assigned a fixed ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">host:port</code>'}})," (see ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">docker-compose.yaml</code>'}}),") so I’m using dummy service discovery to discover and communicate with nrtsearch nodes from the host machine:"),"\n",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token comment"># Simple service discovery for scripts ran from host machine</span>\nSERVICE_DISCOVERY <span class="token operator">=</span> <span class="token punctuation">{</span>\n    <span class="token string">"primary-node"</span><span class="token punctuation">:</span> <span class="token punctuation">(</span><span class="token string">"localhost"</span><span class="token punctuation">,</span> <span class="token number">8000</span><span class="token punctuation">)</span><span class="token punctuation">,</span>\n    <span class="token string">"replica-node-0"</span><span class="token punctuation">:</span> <span class="token punctuation">(</span><span class="token string">"localhost"</span><span class="token punctuation">,</span> <span class="token number">8001</span><span class="token punctuation">)</span><span class="token punctuation">,</span>\n    <span class="token string">"replica-node-1"</span><span class="token punctuation">:</span> <span class="token punctuation">(</span><span class="token string">"localhost"</span><span class="token punctuation">,</span> <span class="token number">8002</span><span class="token punctuation">)</span><span class="token punctuation">,</span>\n<span class="token punctuation">}</span></code></pre></div>'}}),"\n",o.createElement(n.p,null,"In ",o.createElement(n.a,{href:"https://github.com/jedrazb/nrtsearch-tutorial-website-search/blob/master/nrtsearch_client/client.py",target:"_blank",rel:"nofollow noopener noreferrer"},"nrtsearch_client/client.py")," we have the gRPC client which communicates with our cluster nodes:"),"\n",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token decorator annotation punctuation">@lru_cache</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>\n<span class="token keyword">def</span> <span class="token function">get_nrtsearch_client</span><span class="token punctuation">(</span>host<span class="token punctuation">,</span> port<span class="token punctuation">)</span><span class="token punctuation">:</span>\n    channel <span class="token operator">=</span> grpc<span class="token punctuation">.</span>insecure_channel<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">{</span>host<span class="token punctuation">}</span></span><span class="token string">:</span><span class="token interpolation"><span class="token punctuation">{</span>port<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>\n    <span class="token keyword">return</span> LuceneServerStub<span class="token punctuation">(</span>channel<span class="token punctuation">)</span></code></pre></div>'}}),"\n",o.createElement(n.p,null,"The script in ",o.createElement(n.a,{href:"https://github.com/jedrazb/nrtsearch-tutorial-website-search/blob/master/nrtsearch_client/setup_index.py",target:"_blank",rel:"nofollow noopener noreferrer"},"nrtsearch_client/setup_index.py")," creates clients for each node and executes the above commands in order, using the protobuf generated code. You can run the script for index setup locally via ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">make setup_index</code>'}}),"."),"\n",o.createElement(n.p,null,"The process of starting the index is slightly different for replicas and primaries. For example, the ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">start_index_replica()</code>'}})," starts the index in ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">REPLICA</code>'}})," mode and registers to primary to listen for index updates. The ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">primaryAddress="primary-node"</code>'}})," is defined in ",o.createElement(n.a,{href:"https://github.com/jedrazb/nrtsearch-tutorial-website-search/blob/master/docker-compose.yaml#L9",target:"_blank",rel:"nofollow noopener noreferrer"},"docker-compose.yaml")," and the ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">8001</code>'}})," replication port comes from the primary ",o.createElement(n.a,{href:"https://github.com/jedrazb/nrtsearch-tutorial-website-search/blob/master/nrtsearch/nrtsearch-primary-config.yaml#L4",target:"_blank",rel:"nofollow noopener noreferrer"},"server configuration"),". Note that replicas use the internal Docker network to communicate with the primary so we don’t need to expose the replication port."),"\n",o.createElement(n.p,null,"You can verify that the ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">blog_search</code>'}})," index is created on each node by running ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">make index_status</code>'}}),". The output should look like:"),"\n",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">IndicesRequest for: primary-node\nindicesResponse <span class="token punctuation">{</span>\n  indexName: <span class="token string">"blog_search"</span>\n  statsResponse <span class="token punctuation">{</span>\n    dirSize: <span class="token number">96</span>\n    state: <span class="token string">"started"</span>\n    taxonomy <span class="token punctuation">{</span>\n    <span class="token punctuation">}</span>\n    currentSearcher <span class="token punctuation">{</span>\n      segments: <span class="token string">"IndexSearcher(StandardDirectoryReader(segments_1:2:nrt); executor=ExecutorWithParams(sli\nceMaxDocs=250000, sliceMaxSegments=5, virtualShards=1, wrapped=java.util.concurrent.ThreadPoolExecutor@4a\nbd0a9d[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]))"</span>\n    <span class="token punctuation">}</span>\n  <span class="token punctuation">}</span>\n<span class="token punctuation">}</span>\n\nIndicesRequest for: replica-node-0\nindicesResponse <span class="token punctuation">{</span>\n    <span class="token comment">#...</span>\n<span class="token punctuation">}</span></code></pre></div>'}}),"\n",o.createElement(n.p,null,"If you restart the nrtsearch container, you will see that even though the state files are still present in the volume, the index won’t be started. Nrtsearch expects a ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">startIndex</code>'}})," command after server restart. In the ",o.createElement(n.a,{href:"https://github.com/jedrazb/nrtsearch-tutorial-website-search/blob/master/nrtsearch_client/setup_index.py",target:"_blank",rel:"nofollow noopener noreferrer"},"nrtsearch_client/setup_index.py")," script we have extra logic to handle following scenarios:"),"\n",o.createElement(n.ul,null,"\n",o.createElement(n.li,null,o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">blog_search</code>'}})," index is not returned from the ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">indices()</code>'}})," call. It means that the index doesn’t exist. We need to execute all 5 steps to create an index."),"\n",o.createElement(n.li,null,o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">blog_search</code>'}})," index exists but is ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">not_started</code>'}}),". This can happen when you restart a Docker container. We need to just issue the ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">StartIndexRequest</code>'}}),"."),"\n",o.createElement(n.li,null,o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">blog_search</code>'}})," index exists and it is ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">started</code>'}})," - all good, index is already running."),"\n"),"\n",o.createElement(n.p,null,"Great! Now we have a running nrtsearch cluster and our index is started and replicated between primary and replicas. Let’s move on to data ingestion."),"\n",o.createElement(n.h2,{id:"nrtsearch-indexer",style:{position:"relative"}},o.createElement(n.a,{href:"#nrtsearch-indexer","aria-label":"nrtsearch indexer permalink",className:"anchor before"},o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Nrtsearch indexer"),"\n",o.createElement(n.p,null,"In order to ingest data into nrtsearch we can use the ",o.createElement(n.a,{href:"https://github.com/Yelp/nrtsearch/blob/master/clientlib/src/main/proto/yelp/nrtsearch/luceneserver.proto#L135",target:"_blank",rel:"nofollow noopener noreferrer"},"addDocuments")," client method. It allows streaming multiple ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">AddDocumentRequest</code>'}})," to the primary for indexing."),"\n",o.createElement(n.p,null,"A single call to ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">addDocuments</code>'}})," can contain multiple documents in the payload. You can call it a bulk update. It’s more efficient when indexing a large amounts of documents. Therefore, it’s advisable to batch your documents and ingest them in bulk for production use-cases."),"\n",o.createElement(n.blockquote,null,"\n",o.createElement(n.p,null,"There is no transaction log, so you must call commit periodically to make recent changes durable on disk. This means that if a node crashes, all indexed documents since the last commit are lost. (",o.createElement(n.a,{href:"https://nrtsearch.readthedocs.io/en/latest/introduction.html#design",target:"_blank",rel:"nofollow noopener noreferrer"},"docs"),")"),"\n"),"\n",o.createElement(n.p,null,"When ingesting our data to nrtsearch we need to call ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">commit</code>'}})," periodically to ensure our data is persisted. It works very well with streaming frameworks, like Flink, where you can call ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">commit</code>'}})," every time your Flink application checkpoints. The checkpoint is successful if and only if the commit call succeeds."),"\n",o.createElement(n.p,null,"I use a python script, which batches docs and ingests them into the primary and commits the index. Then, we can inspect the replica state to check if index segments were replicated."),"\n",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token comment"># For prod cases we can even make it 1000, taking small value for this tutorial</span>\nBATCH_SIZE <span class="token operator">=</span> <span class="token number">10</span>\n\n\n<span class="token comment"># Load the data processed and saved by the crawler</span>\n<span class="token keyword">def</span> <span class="token function">_load_website_data</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>\n    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"index_resources/website_data.json"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>\n        data <span class="token operator">=</span> json<span class="token punctuation">.</span>load<span class="token punctuation">(</span>f<span class="token punctuation">)</span>\n\n    <span class="token keyword">return</span> data\n\n\n<span class="token comment"># Prepare the request payload</span>\n<span class="token keyword">def</span> <span class="token function">_prepare_document_stream</span><span class="token punctuation">(</span>docs<span class="token punctuation">)</span><span class="token punctuation">:</span>\n    <span class="token keyword">for</span> doc <span class="token keyword">in</span> docs<span class="token punctuation">:</span>\n        fields <span class="token operator">=</span> <span class="token punctuation">{</span>\n            <span class="token string">"url"</span><span class="token punctuation">:</span> AddDocumentRequest<span class="token punctuation">.</span>MultiValuedField<span class="token punctuation">(</span>value<span class="token operator">=</span><span class="token punctuation">[</span>doc<span class="token punctuation">[</span><span class="token string">"url"</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>\n            <span class="token string">"title"</span><span class="token punctuation">:</span> AddDocumentRequest<span class="token punctuation">.</span>MultiValuedField<span class="token punctuation">(</span>value<span class="token operator">=</span><span class="token punctuation">[</span>doc<span class="token punctuation">[</span><span class="token string">"title"</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>\n            <span class="token string">"description"</span><span class="token punctuation">:</span> AddDocumentRequest<span class="token punctuation">.</span>MultiValuedField<span class="token punctuation">(</span>\n                value<span class="token operator">=</span><span class="token punctuation">[</span>doc<span class="token punctuation">[</span><span class="token string">"description"</span><span class="token punctuation">]</span><span class="token punctuation">]</span>\n            <span class="token punctuation">)</span><span class="token punctuation">,</span>\n            <span class="token string">"headings"</span><span class="token punctuation">:</span> AddDocumentRequest<span class="token punctuation">.</span>MultiValuedField<span class="token punctuation">(</span>value<span class="token operator">=</span>doc<span class="token punctuation">[</span><span class="token string">"headings"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>\n            <span class="token string">"content"</span><span class="token punctuation">:</span> AddDocumentRequest<span class="token punctuation">.</span>MultiValuedField<span class="token punctuation">(</span>value<span class="token operator">=</span><span class="token punctuation">[</span>doc<span class="token punctuation">[</span><span class="token string">"content"</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>\n        <span class="token punctuation">}</span>\n\n        <span class="token keyword">yield</span> AddDocumentRequest<span class="token punctuation">(</span>indexName<span class="token operator">=</span>INDEX_NAME<span class="token punctuation">,</span> fields<span class="token operator">=</span>fields<span class="token punctuation">)</span>\n\n\n<span class="token comment"># Use gRPC streaming to send documents for ingestion</span>\n<span class="token keyword">def</span> <span class="token function">index_document_stream</span><span class="token punctuation">(</span>primary_client<span class="token punctuation">,</span> doc_stream<span class="token punctuation">)</span><span class="token punctuation">:</span>\n    response <span class="token operator">=</span> primary_client<span class="token punctuation">.</span>addDocuments<span class="token punctuation">(</span>doc_stream<span class="token punctuation">)</span>\n    <span class="token keyword">return</span> response\n\n\n<span class="token keyword">def</span> <span class="token function">run_indexer</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>\n    <span class="token comment"># Just index data to primary - data will be replicated to other nodes in the cluster</span>\n    host<span class="token punctuation">,</span> port <span class="token operator">=</span> SERVICE_DISCOVERY<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"primary-node"</span><span class="token punctuation">)</span>\n    primary_client <span class="token operator">=</span> get_nrtsearch_client<span class="token punctuation">(</span>host<span class="token punctuation">,</span> port<span class="token punctuation">)</span>\n\n    website_docs <span class="token operator">=</span> _load_website_data<span class="token punctuation">(</span><span class="token punctuation">)</span>\n\n    <span class="token comment"># Split data into chunks for bulk ingestion</span>\n    chunked_website_docs <span class="token operator">=</span> chunked<span class="token punctuation">(</span>website_docs<span class="token punctuation">,</span> BATCH_SIZE<span class="token punctuation">)</span>\n\n    <span class="token comment"># Process each chunk of docs in bulk</span>\n    <span class="token keyword">for</span> idx<span class="token punctuation">,</span> docs_chunk <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>chunked_website_docs<span class="token punctuation">)</span><span class="token punctuation">:</span>\n        doc_stream <span class="token operator">=</span> _prepare_document_stream<span class="token punctuation">(</span>docs<span class="token operator">=</span>docs_chunk<span class="token punctuation">)</span>\n        index_response <span class="token operator">=</span> index_document_stream<span class="token punctuation">(</span>primary_client<span class="token punctuation">,</span> doc_stream<span class="token punctuation">)</span>\n\n    <span class="token comment"># Call commit after docs are ingested</span>\n    commit_response <span class="token operator">=</span> commit_index<span class="token punctuation">(</span>primary_client<span class="token punctuation">)</span></code></pre></div>'}}),"\n",o.createElement(n.p,null,"You can start the script by running ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">make run_indexer</code>'}}),". After the script is done, let’s check the number of docs in each nrtsearch node - to verify that updates were propagated to replicas."),"\n",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token operator">></span> venv/bin/python nrtsearch_client/get_indices.py\nIndicesRequest for: primary-node\nindicesResponse <span class="token punctuation">{</span>\n  indexName: <span class="token string">"blog_search"</span>\n  statsResponse <span class="token punctuation">{</span>\n    maxDoc: <span class="token number">21</span>\n    numDocs: <span class="token number">21</span>\n    <span class="token punctuation">..</span>.\n    currentSearcher <span class="token punctuation">{</span>\n      numDocs: <span class="token number">21</span>\n      <span class="token punctuation">..</span>.\n    <span class="token punctuation">}</span>\n  <span class="token punctuation">}</span>\n<span class="token punctuation">}</span>\n<span class="token punctuation">..</span>.\nIndicesRequest for: replica-node-1\nindicesResponse <span class="token punctuation">{</span>\n  indexName: <span class="token string">"blog_search"</span>\n  statsResponse <span class="token punctuation">{</span>\n    <span class="token punctuation">..</span>.\n    <span class="token punctuation">}</span>\n    searchers <span class="token punctuation">{</span>\n      numDocs: <span class="token number">21</span>\n      <span class="token punctuation">..</span>.\n    <span class="token punctuation">}</span>\n    <span class="token punctuation">..</span>.\n  <span class="token punctuation">}</span>\n<span class="token punctuation">}</span></code></pre></div>'}}),"\n",o.createElement(n.p,null,"We can see that data was successfully replicated between primary and replica nodes - both report 21 docs in their index. Great! 🎉"),"\n",o.createElement(n.h2,{id:"grpcox-web-ui",style:{position:"relative"}},o.createElement(n.a,{href:"#grpcox-web-ui","aria-label":"grpcox web ui permalink",className:"anchor before"},o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"gRPCox web UI"),"\n",o.createElement(n.p,null,o.createElement(n.a,{href:"https://github.com/gusaul/grpcox",target:"_blank",rel:"nofollow noopener noreferrer"},"gRPCox")," is a web UI wrapper for ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">gRPCurl</code>'}}),". It’s a simple but useful tool that lets you interact with gRPC servers. It’s optional for the tutorial but I want to show how it enables ad-hoc communication with the nrtsearch server."),"\n",o.createElement(n.p,null,"The UI was started as one of the services invoked by the ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">make start</code>'}})," command and is accessible on ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">localhost:6969</code>'}}),". The primary is advertised under ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">primary-node</code>'}})," hostname, and replicas are advertised under ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">replica-node</code>'}})," (you can inspect logs to find IP of each replica). The nrtsearch gRPC server runs on port ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">8000</code>'}}),"."),"\n",o.createElement(n.p,null,"Let’s connect to the primary node and run a simple search request to explore the index."),"\n",o.createElement(n.ul,null,"\n",o.createElement(n.li,null,"Connect to primary at ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">primary-node:8000</code>'}})),"\n",o.createElement(n.li,null,"Select ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">luceneserver.LuceneServer</code>'}})," service. You should then see all available gRPC methods and their schemas."),"\n"),"\n",o.createElement(n.p,null,"We will use ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">search</code>'}})," and pass this query to explore docs in the index (note, since the ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">query</code>'}})," field is empty it will return all documents)."),"\n",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<div class="gatsby-highlight" data-language="json"><pre class="language-json"><code class="language-json"><span class="token punctuation">{</span>\n  <span class="token property">"indexName"</span><span class="token operator">:</span> <span class="token string">"blog_search"</span><span class="token punctuation">,</span>\n  <span class="token property">"startHit"</span><span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span>\n  <span class="token property">"topHits"</span><span class="token operator">:</span> <span class="token number">100</span><span class="token punctuation">,</span>\n  <span class="token property">"retrieveFields"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token string">"title"</span><span class="token punctuation">,</span> <span class="token string">"description"</span><span class="token punctuation">,</span> <span class="token string">"url"</span><span class="token punctuation">]</span>\n<span class="token punctuation">}</span></code></pre></div>'}}),"\n",o.createElement(n.p,null,"You should see the search results in the UI."),"\n",o.createElement(a,{image:e.data.mdx.frontmatter.blogImages[1],alt:"gRPCox"}),"\n",o.createElement(n.h2,{id:"custom-search-ranking",style:{position:"relative"}},o.createElement(n.a,{href:"#custom-search-ranking","aria-label":"custom search ranking permalink",className:"anchor before"},o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Custom search ranking"),"\n",o.createElement(n.p,null,"The Lucene’s scoring algorithm considers the frequency and distribution of terms in the document and query vectors. For our scenario it should suffice to return documents that match the user search query. We can add custom weights to prioritize results that contain the search term inside ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">title</code>'}}),", ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">description</code>'}}),", ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">headings</code>'}}),", ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">url</code>'}})," and ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">content</code>'}}),". We can start with simple weights, test our system and refine the algorithm as necessary to improve search results."),"\n",o.createElement(n.p,null,o.createElement(n.a,{href:"https://nrtsearch.readthedocs.io/en/latest/querying_nrtsearch.html",target:"_blank",rel:"nofollow noopener noreferrer"},"Building Nrtsearch Queries")," documentation page contains supported query types along with examples and explanations. Since nrtsearch is based on Apache Lucene, its query types map closely to Lucene queries. It’s possible to customize queries for each field based on specific search requirements. You can combine the queries using a ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">BooleanQuery</code>'}})," with multiple clauses. For example, you could use a ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">MatchPhraseQuery</code>'}})," to search for exact phrases, or a add fuzziness parameters to ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">MatchQuery</code>'}})," to search for approximate matches."),"\n",o.createElement(n.p,null,"The search query used for retrieving hits from ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">blog_search</code>'}})," index is defined in ",o.createElement(n.a,{href:"https://github.com/jedrazb/nrtsearch-tutorial-website-search/blob/master/nrtsearch_client/searcher.py#L41",target:"_blank",rel:"nofollow noopener noreferrer"},"nrtsearch_client/searcher.py"),". We combine multiple ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">MatchQuery</code>'}})," and ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">MatchPhraseQuery</code>'}})," queries to recall and score documents based on their title, description, headings, url and content."),"\n",o.createElement(n.h2,{id:"highlighting-support",style:{position:"relative"}},o.createElement(n.a,{href:"#highlighting-support","aria-label":"highlighting support permalink",className:"anchor before"},o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Highlighting support"),"\n",o.createElement(n.p,null,"Highlights are used to retrieve information about matched terms in a hit. Nrtsearch currently supports the ",o.createElement(n.a,{href:"https://github.com/apache/lucene/blob/main/lucene/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FastVectorHighlighter.java",target:"_blank",rel:"nofollow noopener noreferrer"},"Fast Vector Highlighter")," in Lucene."),"\n",o.createElement(n.p,null,"Results highlighting is configured in the search request’s ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">highlight</code>'}})," field. Nrtsearch returns matched terms in a hit wrapped in ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">pre_tags</code>'}})," and ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">post_tags</code>'}}),". In this tutorial I use the ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">&lt;em></code>'}})," html tag to emphasize the highlighted content."),"\n",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python">search_request <span class="token operator">=</span> SearchRequest<span class="token punctuation">(</span>\n    indexName<span class="token operator">=</span><span class="token string">\'blog_search\'</span><span class="token punctuation">,</span>\n    retrieveFields<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"url"</span><span class="token punctuation">,</span> <span class="token string">"title"</span><span class="token punctuation">,</span> <span class="token string">"description"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>\n    query<span class="token operator">=</span>Query<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">,</span>\n    highlight<span class="token operator">=</span>Highlight<span class="token punctuation">(</span>\n        fields<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"content"</span><span class="token punctuation">,</span> <span class="token string">"content.analyzed"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>\n        settings<span class="token operator">=</span>Highlight<span class="token punctuation">.</span>Settings<span class="token punctuation">(</span>\n            pre_tags<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"&lt;em>"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> post_tags<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"&lt;/em>"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>\n    <span class="token punctuation">)</span><span class="token punctuation">,</span>\n<span class="token punctuation">)</span></code></pre></div>'}}),"\n",o.createElement(n.p,null,"To be able to highlight a field with FVH, the following settings must be enabled when registering the field:"),"\n",o.createElement(n.ul,null,"\n",o.createElement(n.li,null,"The field must be a ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">TEXT</code>'}})," field"),"\n",o.createElement(n.li,null,"The field must be stored: ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">“store: true”</code>'}})),"\n",o.createElement(n.li,null,"The field must have term vectors with positions and offsets: ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">“termVectors: TERMS_POSITIONS_OFFSETS”</code>'}})),"\n",o.createElement(n.li,null,"While not mandatory, the field must be tokenized for the highlights to be useful: ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">“tokenize: true”</code>'}})),"\n"),"\n",o.createElement(n.h2,{id:"client-side-load-balancing",style:{position:"relative"}},o.createElement(n.a,{href:"#client-side-load-balancing","aria-label":"client side load balancing permalink",className:"anchor before"},o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Client-side load balancing"),"\n",o.createElement(n.p,null,"Client-side load balancing allows gRPC clients to distribute load optimally across available nrtsearch replica servers."),"\n",o.createElement(n.p,null,"The configuration to distribute the load across replicas, with round robin policy, looks as follows for our python client:"),"\n",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">get_search_replica_client</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>\n    channel <span class="token operator">=</span> grpc<span class="token punctuation">.</span>insecure_channel<span class="token punctuation">(</span>\n        <span class="token string">"replica-node:8000"</span><span class="token punctuation">,</span> options<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">"grpc.lb_policy_name"</span><span class="token punctuation">,</span> <span class="token string">"round_robin"</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>\n    <span class="token keyword">return</span> LuceneServerStub<span class="token punctuation">(</span>channel<span class="token punctuation">)</span></code></pre></div>'}}),"\n",o.createElement(n.p,null,o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">replica-node</code>'}})," is a DNS record that resolves to multiple IPs - each running a gRPC server at port ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">8000</code>'}}),". The client will distribute requests over the created channel evenly among multiple IPs."),"\n",o.createElement(n.p,null,"In order to verify that ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">replica-node</code>'}})," resolves to our replica IPs, we can run a ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">dig</code>'}})," command within any of the created docker containers. There are two IP addresses in the response, ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">172.20.0.6</code>'}})," and ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">172.20.0.7</code>'}}),", which correspond to the IP addresses of our replicas."),"\n",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">dig replica-node\n\n; &lt;&lt;>> DiG 9.18.13 &lt;&lt;>> replica-node\n;; global options: +cmd\n;; Got answer:\n;; ->>HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 25431\n;; flags: qr rd ra; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 0\n\n;; QUESTION SECTION:\n;replica-node.                  IN      A\n\n;; ANSWER SECTION:\nreplica-node.           600     IN      A       172.20.0.6\nreplica-node.           600     IN      A       172.20.0.7\n\n;; Query time: 3 msec\n;; SERVER: 127.0.0.11#53(127.0.0.11) (UDP)\n;; WHEN: Sun Apr 16 08:34:39 UTC 2023\n;; MSG SIZE  rcvd: 86</code></pre></div>'}}),"\n",o.createElement(n.p,null,"Nrtsearch exposes Prometheus ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">/metrics</code>'}})," endpoint. You can set up Grafana dashboards to see how search traffic is balanced between your running replicas."),"\n",o.createElement(n.h2,{id:"search-ui",style:{position:"relative"}},o.createElement(n.a,{href:"#search-ui","aria-label":"search ui permalink",className:"anchor before"},o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Search UI"),"\n",o.createElement(n.p,null,"Our Search UI is a simple server-side React app. It was bootstrapped with ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">npx create-next-app</code>'}})," command. I used ",o.createElement(n.a,{href:"https://github.com/elastic/search-ui",target:"_blank",rel:"nofollow noopener noreferrer"},"@elastic/search-ui")," React components to define the app UI in ",o.createElement(n.a,{href:"https://github.com/jedrazb/nrtsearch-tutorial-website-search/blob/master/search_ui/src/pages/index.tsx",target:"_blank",rel:"nofollow noopener noreferrer"},"less than 100 lines of frontend code"),". The library supports custom connectors. The Search UI is ",o.createElement(n.a,{href:"https://github.com/jedrazb/nrtsearch-tutorial-website-search/blob/master/search_ui/src/connector/Connector.tsx",target:"_blank",rel:"nofollow noopener noreferrer"},"connected")," to our searcher API - a simple Flask server with ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">/search</code>'}})," endpoint."),"\n",o.createElement(n.p,null,"It was started by running ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">make start</code>'}})," and should be accessible on ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">localhost:3000</code>'}}),". You can make a few search queries to see how our custom search ranking works."),"\n",o.createElement(a,{image:e.data.mdx.frontmatter.blogImages[0],alt:"Search UI"}),"\n",o.createElement(n.h2,{id:"putting-it-all-together",style:{position:"relative"}},o.createElement(n.a,{href:"#putting-it-all-together","aria-label":"putting it all together permalink",className:"anchor before"},o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg>'}})),"Putting it all together"),"\n",o.createElement(n.p,null,"Configuration for every service mentioned in this tutorial is in the ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">docker-compose.yaml</code>'}})," file. In order to start this project locally you need to execute four commands:"),"\n",o.createElement(n.ul,null,"\n",o.createElement(n.li,null,o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">make start</code>'}})," - starts the nrtsearch cluster, search UI and search API server, and the gRPC web UI. It also generates nrtsearch client python code using ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">protoc</code>'}})," compiler."),"\n",o.createElement(n.li,null,o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">make start_index</code>'}})," - starts the ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">blog_search</code>'}})," index"),"\n",o.createElement(n.li,null,o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">make run_crawler</code>'}})," - crawls web data"),"\n",o.createElement(n.li,null,o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">make run_indexer</code>'}})," - indexes crawled web data"),"\n"),"\n",o.createElement(n.p,null,"You can access the Search UI on your host machine ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">localhost:3000</code>'}})," to issue search queries. The web UI for sending gRPC commands to nrtsearch is available at ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">localhost:6969</code>'}}),"."),"\n",o.createElement(n.p,null,"You can index more web data by editing and adding sources to the ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">crawler.py</code>'}})," code. Keep in mind that when crawling websites with scripts, it is crucial to respect the ",o.createElement(n.span,{dangerouslySetInnerHTML:{__html:'<code class="language-text">robots.txt</code>'}})," file. Some websites, including Wikipedia offer ",o.createElement(n.a,{href:"https://en.wikipedia.org/wiki/Wikipedia:Database_download",target:"_blank",rel:"nofollow noopener noreferrer"},"database dumps")," to limit unnecessary crawling."),"\n",o.createElement(n.p,null,"I hope this tutorial is a helpful introduction to data indexing with nrtsearch. Happy hacking!"))}var r=function(e){void 0===e&&(e={});const{wrapper:n}=Object.assign({},(0,s.R)(),e.components);return n?o.createElement(n,e,o.createElement(l,e)):l(e)};var c=a(4794),p=a(8156),i=a.n(p),u=a(2532),d=a(39),h=a(9203),m=a(2907),g=a(9379),k=a(5181),y=a(3303),_=a(4799),b=a(1863),f=a(7821),E=a(5765),w=a(4039),x=a(1929);const S={Link:c.Link,ImageGallery:g.A,ImageComponent:k.A,Container:b.mc,Column:b.VP,MakeItBigContainer:b.r,ThreePhotosContainer:b.Rq,LazyIframe:y.A,StatefulSliderPicker:w.a,StatefulBlockPicker:w.A};let I=function(e){function n(){return e.apply(this,arguments)||this}return(0,t.A)(n,e),n.prototype.render=function(){const{children:e}=this.props,n=this.props.data.mdx,a=i()(this.props,"data.site.siteMetadata.title"),t=i()(this.props,"data.site.siteMetadata.siteUrl");let{previous:l,next:r}=this.props.pageContext;const p=n.frontmatter.ogimage,g=p&&(0,u.d)(p),k=i()(n,"fields.category"),y=t+"/"+k+n.fields.slug,b={"@context":"https://schema.org","@type":"BlogPosting",headline:n.frontmatter.title,datePublished:n.frontmatter.date,url:y,author:[{"@type":"Person",name:"Jedr Blaszyk",url:"https://j.blaszyk.me/"}]};return o.createElement(h.A,{location:this.props.location,title:a,tocComponent:o.createElement(x.A,n.tableOfContents)},o.createElement(m.A,{title:n.frontmatter.title,description:n.frontmatter.spoiler,slug:n.fields.slug,image:g,structuredData:b}),o.createElement("main",null,o.createElement("article",{className:"post"},o.createElement("header",{id:"post-header"},o.createElement("h1",{style:{color:"var(--textTitle)",marginTop:"1.5rem",marginBottom:"0.5rem"}},n.frontmatter.title),o.createElement(c.Link,{style:{boxShadow:"none",textDecoration:"none",color:"var(--textLink)",fontFamily:"Montserrat, sans-serif"},to:"/tech-blog/",rel:"bookmark"},o.createElement("p",null,"Tech Blog")),o.createElement("p",{style:{...(0,E.hs)(-.2),display:"block",marginBottom:(0,E.di)(1),marginTop:(0,E.di)(-.8)}},(0,f.Wy)(n.frontmatter.date),o.createElement("span",{style:{margin:"0 0.15rem"}}," • "),(0,f.Bt)(n.fields.timeToRead.minutes))),o.createElement(s.x,{components:S},e))),o.createElement("aside",null,o.createElement("nav",null,o.createElement("ul",{style:{display:"flex",flexWrap:"wrap",justifyContent:"space-between",listStyle:"none",padding:0,marginLeft:0}},o.createElement("li",null,l&&o.createElement(c.Link,{to:"/"+k+l.fields.slug,rel:"prev"},"← ",l.frontmatter.title)),o.createElement("li",null,r&&o.createElement(c.Link,{to:"/"+k+r.fields.slug,rel:"next"},r.frontmatter.title," →")))),o.createElement("h3",{style:{fontFamily:"Montserrat, sans-serif",marginTop:(0,E.di)(.25)}},o.createElement(c.Link,{style:{boxShadow:"none",textDecoration:"none",color:"var(--textLink)",fontSize:(0,E.di)(.8)},to:"/"},"Jedr's Blog")," • ",o.createElement(c.Link,{style:{boxShadow:"none",textDecoration:"none",color:"var(--textLink)",fontSize:(0,E.di)(.8)},to:"/tech-blog/"},"Tech Blog")),o.createElement(d.A),o.createElement(_.A,{url:y,id:n.fields.slug,title:n.frontmatter.title})))},n}(o.Component);function T(e){return o.createElement(I,e,o.createElement(r,e))}}}]);
//# sourceMappingURL=component---src-templates-tech-blog-post-js-content-file-path-content-tech-blog-nrtsearch-tutorial-website-search-index-mdx-c66e1e01a526840c55d9.js.map